{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a8b0f",
   "metadata": {},
   "source": [
    "# Q1: Install Spark and PySpark\n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7e4589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.1.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a389d",
   "metadata": {},
   "source": [
    "# Q2: Yellow October 2024\n",
    "\n",
    "Read the October 2024 Yellow into a Spark Dataframe.\n",
    "\n",
    "Repartition the Dataframe to 4 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61fa7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/23 20:41:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet(\"yellow_tripdata_2025-11.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af7a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       7| 2025-11-01 00:13:25|  2025-11-01 00:13:25|              1|         1.68|         1|                 N|          43|         186|           1|       14.9|  0.0|    0.5|       1.5|         0.0|                  1.0|       22.15|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:49:07|  2025-11-01 01:01:22|              1|         2.28|         1|                 N|         142|         237|           1|       14.2|  1.0|    0.5|      4.99|         0.0|                  1.0|       24.94|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-11-01 00:07:19|  2025-11-01 00:20:41|              0|          2.7|         1|                 N|         163|         238|           1|       15.6| 4.25|    0.5|      4.27|         0.0|                  1.0|       25.62|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:00:00|  2025-11-01 01:01:03|              3|        12.87|         1|                 N|         138|         261|           1|       66.7|  6.0|    0.5|       0.0|        6.94|                  1.0|       86.14|                 2.5|       1.75|              0.75|\n",
      "|       1| 2025-11-01 00:18:50|  2025-11-01 00:49:32|              0|          8.4|         1|                 N|         138|          37|           2|       39.4| 7.75|    0.5|       0.0|         0.0|                  1.0|       48.65|                 0.0|       1.75|               0.0|\n",
      "|       2| 2025-11-01 00:21:11|  2025-11-01 00:31:39|              1|         0.85|         1|                 N|          90|         100|           2|       10.7|  1.0|    0.5|       0.0|         0.0|                  1.0|       16.45|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:07:31|  2025-11-01 00:25:44|              1|         3.01|         1|                 N|         142|         170|           1|       19.1|  1.0|    0.5|       1.0|         0.0|                  1.0|       25.85|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:46:52|  2025-11-01 01:38:55|              3|         3.82|         1|                 N|         237|         144|           1|       42.2|  1.0|    0.5|      9.59|         0.0|                  1.0|       57.54|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:56:59|  2025-11-01 01:02:05|              1|         0.89|         1|                 N|         162|         161|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|       12.95|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:10:43|  2025-11-01 00:39:25|              3|         2.28|         1|                 N|         234|         162|           1|       24.0|  1.0|    0.5|      8.93|         0.0|                  1.0|       38.68|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-11-01 00:00:03|  2025-11-01 00:42:25|              2|          3.3|         1|                 N|         158|          88|           1|       35.9| 4.25|    0.5|      2.35|         0.0|                  1.0|        44.0|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-11-01 00:43:53|  2025-11-01 00:56:46|              2|          1.5|         1|                 N|          88|         148|           1|       12.8| 4.25|    0.5|       1.0|         0.0|                  1.0|       19.55|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-11-01 00:58:02|  2025-11-01 01:32:36|              2|          4.7|         1|                 N|         148|         236|           1|       32.4| 4.25|    0.5|       9.5|         0.0|                  1.0|       47.65|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:52:48|  2025-11-01 01:23:18|              1|         5.61|         1|                 N|          87|         255|           1|       33.1|  1.0|    0.5|       0.0|         0.0|                  1.0|       38.85|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-11-01 00:05:53|  2025-11-01 00:58:03|              1|          3.9|         1|                 N|         231|          43|           1|       40.8| 4.25|    0.5|       0.0|         0.0|                  1.0|       46.55|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:13:44|  2025-11-01 00:19:30|              2|         1.14|         1|                 N|         141|         262|           1|        7.9|  1.0|    0.5|       2.0|         0.0|                  1.0|        14.9|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-11-01 00:03:18|  2025-11-01 00:06:48|              2|          0.6|         1|                 N|         238|          24|           1|        5.1|  1.0|    0.5|      1.52|         0.0|                  1.0|        9.12|                 0.0|        0.0|               0.0|\n",
      "|       1| 2025-11-01 00:19:55|  2025-11-01 00:45:37|              1|          4.3|         1|                 N|         236|         147|           1|       24.7|  1.0|    0.5|       2.0|         0.0|                  1.0|        29.2|                 0.0|        0.0|               0.0|\n",
      "|       1| 2025-11-01 00:45:55|  2025-11-01 01:11:30|              1|          3.0|         1|                 N|         231|         137|           1|       24.0| 4.25|    0.5|       3.0|         0.0|                  1.0|       32.75|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-11-01 00:11:12|  2025-11-01 00:15:02|              1|         0.69|         1|                 N|         237|         237|           2|        6.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        11.5|                 2.5|        0.0|               0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217d482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=df.repartition(4)\n",
    "\n",
    "df.write.parquet(\"yellow/2025/11/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4185cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0B\tyellow/2025/11/_SUCCESS\n",
      " 25M\tyellow/2025/11/part-00000-3aa279a6-0d5b-4059-857f-2fae1521efdb-c000.snappy.parquet\n",
      " 25M\tyellow/2025/11/part-00001-3aa279a6-0d5b-4059-857f-2fae1521efdb-c000.snappy.parquet\n",
      " 25M\tyellow/2025/11/part-00002-3aa279a6-0d5b-4059-857f-2fae1521efdb-c000.snappy.parquet\n",
      " 25M\tyellow/2025/11/part-00003-3aa279a6-0d5b-4059-857f-2fae1521efdb-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!du -h yellow/2025/11/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d46bc",
   "metadata": {},
   "source": [
    "# Q3: Count records \n",
    "\n",
    "How many taxi trips were there on the 15th of November?\n",
    "\n",
    "Consider only trips that started on the 15th of November."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4638d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|count(pickup_date)|\n",
      "+------------------+\n",
      "|            162604|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.tpep_pickup_datetime)) \\\n",
    "    .filter(F.col('pickup_date') == '2025-11-15') \\\n",
    "    .select(F.count('pickup_date')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a265c1",
   "metadata": {},
   "source": [
    "# Q4: Longest trip\n",
    "\n",
    "What is the length of the longest trip in the dataset in hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fccec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              diff|\n",
      "+------------------+\n",
      "| 90.64666666666666|\n",
      "| 76.94833333333334|\n",
      "| 76.21388888888889|\n",
      "| 69.28861111111111|\n",
      "| 67.08055555555555|\n",
      "| 63.36833333333333|\n",
      "|56.382222222222225|\n",
      "|48.147777777777776|\n",
      "| 47.47833333333333|\n",
      "| 45.44416666666667|\n",
      "| 44.04333333333334|\n",
      "|43.230555555555554|\n",
      "|42.720555555555556|\n",
      "|41.614444444444445|\n",
      "| 41.50333333333333|\n",
      "| 39.33305555555555|\n",
      "|38.074444444444445|\n",
      "| 37.91111111111111|\n",
      "| 34.87027777777778|\n",
      "| 30.53388888888889|\n",
      "+------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('diff', \n",
    "    (F.unix_timestamp('tpep_dropoff_datetime') - F.unix_timestamp('tpep_pickup_datetime'))/3600) \\\n",
    "    .select(\"diff\") \\\n",
    "    .orderBy(F.col(\"diff\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac06dc3",
   "metadata": {},
   "source": [
    "# Q5: User Interface\n",
    "\n",
    "Sparkâ€™s User Interface which shows the application's dashboard runs on which local port?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb45825",
   "metadata": {},
   "source": [
    "Answer: `4040`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9c588",
   "metadata": {},
   "source": [
    "# Q6: Least frequent pickup location zone\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark:\n",
    "\n",
    "```bash\n",
    "wget https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
    "```\n",
    "\n",
    "Using the zone lookup data and the Yellow October 2024 data, what is the name of the LEAST frequent pickup location Zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d86e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Zone|count|\n",
      "+--------------------+-----+\n",
      "|Governor's Island...|    1|\n",
      "|Eltingville/Annad...|    1|\n",
      "|       Arden Heights|    1|\n",
      "|       Port Richmond|    3|\n",
      "|       Rikers Island|    4|\n",
      "|   Rossville/Woodrow|    4|\n",
      "|         Great Kills|    4|\n",
      "| Green-Wood Cemetery|    4|\n",
      "|         Jamaica Bay|    5|\n",
      "|         Westerleigh|   12|\n",
      "|New Dorp/Midland ...|   14|\n",
      "|       West Brighton|   14|\n",
      "|             Oakwood|   14|\n",
      "|        Crotona Park|   14|\n",
      "|       Willets Point|   15|\n",
      "|Breezy Point/Fort...|   16|\n",
      "|Saint George/New ...|   17|\n",
      "|       Broad Channel|   18|\n",
      "|     Mariners Harbor|   21|\n",
      "|Heartland Village...|   22|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_lookup = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .csv(\"taxi_zone_lookup.csv\")\n",
    "\n",
    "df_lookup.createOrReplaceTempView(\"zone_lookup\")\n",
    "df.createOrReplaceTempView(\"trip_data\")\n",
    "\n",
    "df \\\n",
    "    .join(df_lookup, df.PULocationID == df_lookup.LocationID) \\\n",
    "    .groupBy(\"Zone\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\") \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-engineering-zoomcamp-homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
